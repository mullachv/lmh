{
  "model_embedding_dimensions": {
    "meta-llama/Llama-2-7b-hf": 4096,
    "all-MiniLM-L6-v2": 384,
    "all-mpnet-base-v2": 768,
    "all-distilroberta-v1": 768,
    "bert-base-uncased": 768,
    "roberta-base": 768,
    "distilbert-base-uncased": 768
  },
  "embedding_normalization": {
    "normalized_to_unit_sphere": {
      "all-MiniLM-L6-v2": {"mean_norm": 1.000000, "std_norm": 0.000000},
      "all-mpnet-base-v2": {"mean_norm": 1.000000, "std_norm": 0.000000},
      "all-distilroberta-v1": {"mean_norm": 1.000000, "std_norm": 0.000000}
    },
    "not_normalized": {
      "bert-base-uncased": {"mean_norm": 9.435158, "std_norm": 0.432268},
      "roberta-base": {"mean_norm": 12.411178, "std_norm": 0.397881},
      "distilbert-base-uncased": {"mean_norm": 8.433428, "std_norm": 0.436561},
      "meta-llama/Llama-2-7b-hf": {"mean_norm": 63.830213, "std_norm": 6.503225}
    }
  },
  "dimension_groups": {
    "4096D": ["meta-llama/Llama-2-7b-hf"],
    "768D": [
      "all-mpnet-base-v2",
      "all-distilroberta-v1", 
      "bert-base-uncased",
      "roberta-base",
      "distilbert-base-uncased"
    ],
    "384D": ["all-MiniLM-L6-v2"]
  },
  "model_categories": {
    "large_language_models": {
      "meta-llama/Llama-2-7b-hf": 4096
    },
    "sentence_transformers": {
      "all-MiniLM-L6-v2": 384,
      "all-mpnet-base-v2": 768,
      "all-distilroberta-v1": 768
    },
    "huggingface_transformers": {
      "bert-base-uncased": 768,
      "roberta-base": 768,
      "distilbert-base-uncased": 768
    }
  },
  "performance_ranking": {
    "clustering_silhouette": {
      "roberta-base": 0.120,
      "meta-llama/Llama-2-7b-hf": 0.105,
      "bert-base-uncased": 0.083,
      "distilbert-base-uncased": 0.083,
      "all-mpnet-base-v2": 0.036,
      "all-MiniLM-L6-v2": 0.034,
      "all-distilroberta-v1": 0.034
    },
    "average_cosine_distance": {
      "all-MiniLM-L6-v2": 0.884,
      "all-mpnet-base-v2": 0.870,
      "all-distilroberta-v1": 0.858,
      "bert-base-uncased": 0.309,
      "distilbert-base-uncased": 0.236,
      "meta-llama/Llama-2-7b-hf": 0.342,
      "roberta-base": 0.030
    }
  },
  "metadata": {
    "last_updated": "2025-09-28",
    "total_models": 7,
    "unique_dimensions": [384, 768, 4096],
    "dataset_size": 130,
    "analysis_notes": {
      "best_clustering": "roberta-base (0.120 silhouette)",
      "best_separation": "meta-llama/Llama-2-7b-hf (0.342 avg distance, 4096D)",
      "most_efficient": "all-MiniLM-L6-v2 (384D, good for quick analysis)",
      "most_compact": "roberta-base (0.030 avg distance, tight clustering)",
      "normalization_impact": "Sentence Transformers models are normalized to unit sphere, while BERT/RoBERTa/LLaMA are not normalized"
    }
  }
}
