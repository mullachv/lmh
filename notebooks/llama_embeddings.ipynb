{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLaMA Embeddings for Manifold Distance Analysis\n",
        "\n",
        "This notebook extracts embeddings from LLaMA model for the hallucination detection project.\n",
        "We'll analyze the embedding space to identify manifolds and measure distances.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import umap\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Sample Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load sample prompts\n",
        "with open('../data/sample_prompts.json', 'r') as f:\n",
        "    prompts = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(prompts)} sample prompts:\")\n",
        "for i, prompt in enumerate(prompts):\n",
        "    print(f\"{i+1}. {prompt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load LLaMA Model and Tokenizer\n",
        "\n",
        "We'll use a smaller LLaMA model for faster processing. You can change this to a larger model if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load LLaMA model and tokenizer\n",
        "# Using a smaller model for faster processing - you can change this to larger models\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"  # or \"meta-llama/Llama-2-13b-hf\" for larger model\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded successfully. Hidden size: {model.config.hidden_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract Embeddings\n",
        "\n",
        "We'll extract embeddings by taking the mean of the last hidden states for each prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_embeddings(texts, model, tokenizer, device):\n",
        "    \"\"\"Extract embeddings for a list of texts\"\"\"\n",
        "    embeddings = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for text in tqdm(texts, desc=\"Extracting embeddings\"):\n",
        "            # Tokenize\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "            \n",
        "            # Get model outputs\n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "            # Take mean of last hidden states (excluding padding tokens)\n",
        "            attention_mask = inputs['attention_mask']\n",
        "            last_hidden_states = outputs.last_hidden_state\n",
        "            \n",
        "            # Mask out padding tokens and compute mean\n",
        "            masked_embeddings = last_hidden_states * attention_mask.unsqueeze(-1)\n",
        "            mean_embedding = masked_embeddings.sum(dim=1) / attention_mask.sum(dim=1, keepdim=True)\n",
        "            \n",
        "            embeddings.append(mean_embedding.cpu().numpy())\n",
        "    \n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "# Extract embeddings for all prompts\n",
        "print(\"Extracting embeddings...\")\n",
        "embeddings = extract_embeddings(prompts, model, tokenizer, device)\n",
        "print(f\"Embeddings shape: {embeddings.shape}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
